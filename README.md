This is my experiment about privacy-preserving fairness audit of machine learning model.
- In order to audit fairness of model
- zero knowldege proof can provide integrity and publicly verifiable

# Environment
- cmake
- libsnark
- python3, c++

# modules
- model 
- proof

# run
After clone this project, run
- `cmake -B build`
- `cmake --build build`
- executable file in build/src/main, then run `./build/src/main`

